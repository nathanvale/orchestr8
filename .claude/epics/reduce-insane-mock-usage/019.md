---
epic: reduce-insane-mock-usage
task: 019
title: Implement mock usage monitoring and reporting
size: Medium
parallel: true
depends_on: [011]
status: pending
created: 2025-09-20T02:15:00Z
updated: 2025-09-20T02:15:00Z
---

# Task 019: Implement mock usage monitoring and reporting

## Objective

Implement comprehensive monitoring and reporting systems to track mock usage
across the codebase, prevent mock creep, and provide actionable insights for
ongoing mock reduction efforts.

## Background

To maintain the benefits of mock reduction and prevent regression to
over-mocking patterns, we need continuous monitoring of mock usage. This system
will track mock density, identify anti-patterns, and provide regular reports to
maintain healthy testing practices.

## Requirements

### 1. Mock Usage Tracking

Monitor key metrics:

- **Mock count per file** and trends over time
- **Mock density by test tier** (unit/integration/e2e)
- **Mock complexity distribution** (simple vs complex mocks)
- **Anti-pattern detection** (over-mocking, inappropriate mock usage)
- **Mock type distribution** (internal vs external, service types)

### 2. Automated Analysis

Implement analysis systems:

- **Daily mock usage reports** for team awareness
- **Pull request mock analysis** to catch regressions
- **Trend analysis** to identify concerning patterns
- **Threshold monitoring** with alerts for excessive mock usage
- **Quality metrics** correlation with mock usage

### 3. Reporting Dashboard

Create comprehensive reporting:

- **Real-time mock metrics** dashboard
- **Historical trend analysis** and visualizations
- **Team performance metrics** and comparisons
- **Actionable recommendations** for improvement
- **Integration with CI/CD** for automated feedback

## Implementation Details

### 1. Mock Usage Tracker

```typescript
// src/monitoring/mock-usage-tracker.ts

export interface MockMetrics {
  timestamp: string
  totalMocks: number
  mocksByFile: Record<string, number>
  mocksByType: Record<MockType, number>
  mocksByTier: Record<TestTier, number>
  mockComplexity: MockComplexityMetrics
  antiPatterns: AntiPattern[]
  qualityScore: number
  trendAnalysis: TrendAnalysis
}

export interface MockComplexityMetrics {
  simple: number
  moderate: number
  complex: number
  impossible: number
  averageComplexity: number
}

export interface AntiPattern {
  type: AntiPatternType
  severity: 'low' | 'medium' | 'high' | 'critical'
  location: string
  description: string
  recommendation: string
  affectedTests: number
}

export enum AntiPatternType {
  OVER_MOCKING = 'over-mocking',
  INTERNAL_MOCKING = 'internal-mocking',
  UTILITY_MOCKING = 'utility-mocking',
  CONSOLE_MOCKING = 'console-mocking',
  COMPLEX_MOCK_SETUP = 'complex-mock-setup',
  MOCK_LEAKAGE = 'mock-leakage',
  INAPPROPRIATE_TIER = 'inappropriate-tier',
}

export enum TestTier {
  UNIT = 'unit',
  INTEGRATION = 'integration',
  E2E = 'e2e',
  SMOKE = 'smoke',
}

export enum MockType {
  INTERNAL = 'internal',
  EXTERNAL = 'external',
  UTILITY = 'utility',
  CONSOLE = 'console',
  SYSTEM = 'system',
  FRAMEWORK = 'framework',
}

export class MockUsageTracker {
  private metricsHistory: MockMetrics[] = []
  private readonly thresholds: MockThresholds

  constructor(thresholds: MockThresholds) {
    this.thresholds = thresholds
  }

  async collectMetrics(testDirectories: string[]): Promise<MockMetrics> {
    const mockAnalysis = await this.analyzeMockUsage(testDirectories)
    const antiPatterns = this.detectAntiPatterns(mockAnalysis)
    const qualityScore = this.calculateQualityScore(mockAnalysis, antiPatterns)
    const trendAnalysis = this.analyzeTrends(mockAnalysis)

    const metrics: MockMetrics = {
      timestamp: new Date().toISOString(),
      totalMocks: mockAnalysis.totalMocks,
      mocksByFile: mockAnalysis.mocksByFile,
      mocksByType: mockAnalysis.mocksByType,
      mocksByTier: mockAnalysis.mocksByTier,
      mockComplexity: mockAnalysis.complexityMetrics,
      antiPatterns,
      qualityScore,
      trendAnalysis,
    }

    this.metricsHistory.push(metrics)
    await this.persistMetrics(metrics)

    return metrics
  }

  private async analyzeMockUsage(
    testDirectories: string[],
  ): Promise<MockAnalysisResult> {
    const mocksByFile: Record<string, number> = {}
    const mocksByType: Record<MockType, number> = {}
    const mocksByTier: Record<TestTier, number> = {}
    const complexityDistribution: Record<string, number> = {}

    let totalMocks = 0

    for (const directory of testDirectories) {
      const testFiles = await this.findTestFiles(directory)
      const tier = this.determineTierFromPath(directory)

      for (const file of testFiles) {
        const content = await fs.readFile(file, 'utf-8')
        const fileMocks = this.extractMocksFromFile(content)

        mocksByFile[file] = fileMocks.length
        totalMocks += fileMocks.length

        // Count by tier
        if (!mocksByTier[tier]) mocksByTier[tier] = 0
        mocksByTier[tier] += fileMocks.length

        // Count by type and complexity
        fileMocks.forEach((mock) => {
          if (!mocksByType[mock.type]) mocksByType[mock.type] = 0
          mocksByType[mock.type]++

          if (!complexityDistribution[mock.complexity]) {
            complexityDistribution[mock.complexity] = 0
          }
          complexityDistribution[mock.complexity]++
        })
      }
    }

    return {
      totalMocks,
      mocksByFile,
      mocksByType,
      mocksByTier,
      complexityMetrics: this.calculateComplexityMetrics(
        complexityDistribution,
      ),
    }
  }

  private detectAntiPatterns(analysis: MockAnalysisResult): AntiPattern[] {
    const antiPatterns: AntiPattern[] = []

    // Detect over-mocking (>2 mocks per test file)
    Object.entries(analysis.mocksByFile).forEach(([file, count]) => {
      if (count > this.thresholds.maxMocksPerFile) {
        antiPatterns.push({
          type: AntiPatternType.OVER_MOCKING,
          severity:
            count > this.thresholds.maxMocksPerFile * 2 ? 'critical' : 'high',
          location: file,
          description: `File contains ${count} mocks (threshold: ${this.thresholds.maxMocksPerFile})`,
          recommendation:
            'Consider converting to integration test or breaking into smaller tests',
          affectedTests: 1,
        })
      }
    })

    // Detect internal module mocking
    if (
      analysis.mocksByType[MockType.INTERNAL] > this.thresholds.maxInternalMocks
    ) {
      antiPatterns.push({
        type: AntiPatternType.INTERNAL_MOCKING,
        severity: 'high',
        location: 'codebase-wide',
        description: `${analysis.mocksByType[MockType.INTERNAL]} internal module mocks detected`,
        recommendation: 'Replace internal mocks with real implementations',
        affectedTests: analysis.mocksByType[MockType.INTERNAL],
      })
    }

    // Detect utility mocking
    if (
      analysis.mocksByType[MockType.UTILITY] > this.thresholds.maxUtilityMocks
    ) {
      antiPatterns.push({
        type: AntiPatternType.UTILITY_MOCKING,
        severity: 'medium',
        location: 'codebase-wide',
        description: `${analysis.mocksByType[MockType.UTILITY]} utility function mocks detected`,
        recommendation: 'Use real utility functions with proper test data',
        affectedTests: analysis.mocksByType[MockType.UTILITY],
      })
    }

    // Detect console mocking
    if (
      analysis.mocksByType[MockType.CONSOLE] > this.thresholds.maxConsoleMocks
    ) {
      antiPatterns.push({
        type: AntiPatternType.CONSOLE_MOCKING,
        severity: 'low',
        location: 'codebase-wide',
        description: `${analysis.mocksByType[MockType.CONSOLE]} console mocks detected`,
        recommendation:
          'Remove console mocks and use test environment configuration',
        affectedTests: analysis.mocksByType[MockType.CONSOLE],
      })
    }

    // Detect inappropriate test tier usage
    const unitMockRatio =
      analysis.mocksByTier[TestTier.UNIT] / analysis.totalMocks
    if (unitMockRatio > this.thresholds.maxUnitMockRatio) {
      antiPatterns.push({
        type: AntiPatternType.INAPPROPRIATE_TIER,
        severity: 'medium',
        location: 'unit tests',
        description: `${(unitMockRatio * 100).toFixed(1)}% of mocks are in unit tests`,
        recommendation: 'Move heavily mocked tests to integration tier',
        affectedTests: analysis.mocksByTier[TestTier.UNIT],
      })
    }

    return antiPatterns
  }

  private calculateQualityScore(
    analysis: MockAnalysisResult,
    antiPatterns: AntiPattern[],
  ): number {
    let score = 100

    // Penalize for high mock count
    const mockPenalty = Math.min(
      40,
      (analysis.totalMocks / this.thresholds.targetTotalMocks) * 20,
    )
    score -= mockPenalty

    // Penalize for anti-patterns
    const antiPatternPenalty = antiPatterns.reduce((penalty, pattern) => {
      const severityWeight = { low: 2, medium: 5, high: 10, critical: 20 }
      return penalty + severityWeight[pattern.severity]
    }, 0)
    score -= Math.min(40, antiPatternPenalty)

    // Bonus for good practices
    const externalRatio =
      analysis.mocksByType[MockType.EXTERNAL] / analysis.totalMocks
    if (externalRatio > 0.7) {
      score += 10 // Bonus for mostly external mocks
    }

    const integrationRatio =
      analysis.mocksByTier[TestTier.INTEGRATION] / analysis.totalMocks
    if (integrationRatio > 0.4) {
      score += 10 // Bonus for good integration test usage
    }

    return Math.max(0, Math.min(100, score))
  }

  private analyzeTrends(analysis: MockAnalysisResult): TrendAnalysis {
    if (this.metricsHistory.length < 2) {
      return {
        mockCountTrend: 'stable',
        qualityTrend: 'stable',
        antiPatternTrend: 'stable',
        recommendations: [],
      }
    }

    const previous = this.metricsHistory[this.metricsHistory.length - 1]
    const current = analysis

    const mockCountChange =
      (current.totalMocks - previous.totalMocks) / previous.totalMocks
    const qualityChange =
      this.calculateQualityScore(current, []) - previous.qualityScore

    return {
      mockCountTrend: this.determineTrend(mockCountChange),
      qualityTrend: this.determineTrend(qualityChange, true),
      antiPatternTrend: this.determineAntiPatternTrend(previous, current),
      recommendations: this.generateTrendRecommendations(
        mockCountChange,
        qualityChange,
      ),
    }
  }

  private async persistMetrics(metrics: MockMetrics): Promise<void> {
    const metricsDir = '__tests__/metrics'
    await fs.ensureDir(metricsDir)

    // Save current metrics
    const timestamp = metrics.timestamp.replace(/[:.]/g, '-')
    await fs.writeFile(
      path.join(metricsDir, `mock-metrics-${timestamp}.json`),
      JSON.stringify(metrics, null, 2),
    )

    // Update latest metrics
    await fs.writeFile(
      path.join(metricsDir, 'latest-mock-metrics.json'),
      JSON.stringify(metrics, null, 2),
    )

    // Maintain metrics history
    await fs.writeFile(
      path.join(metricsDir, 'mock-metrics-history.json'),
      JSON.stringify(this.metricsHistory, null, 2),
    )
  }
}

interface MockThresholds {
  maxMocksPerFile: number
  maxInternalMocks: number
  maxUtilityMocks: number
  maxConsoleMocks: number
  maxUnitMockRatio: number
  targetTotalMocks: number
}

interface TrendAnalysis {
  mockCountTrend: 'improving' | 'degrading' | 'stable'
  qualityTrend: 'improving' | 'degrading' | 'stable'
  antiPatternTrend: 'improving' | 'degrading' | 'stable'
  recommendations: string[]
}
```

### 2. Pull Request Analysis

```typescript
// scripts/pr-mock-analysis.ts

export class PullRequestMockAnalyzer {
  async analyzePullRequest(
    baseBranch: string,
    currentBranch: string,
  ): Promise<PullRequestAnalysis> {
    const baseMetrics = await this.collectBranchMetrics(baseBranch)
    const currentMetrics = await this.collectBranchMetrics(currentBranch)

    const mockChanges = this.calculateMockChanges(baseMetrics, currentMetrics)
    const riskAssessment = this.assessRiskLevel(mockChanges)
    const recommendations = this.generateRecommendations(
      mockChanges,
      riskAssessment,
    )

    return {
      baseBranch,
      currentBranch,
      mockChanges,
      riskAssessment,
      recommendations,
      shouldBlock:
        riskAssessment.level === 'high' || riskAssessment.level === 'critical',
    }
  }

  private calculateMockChanges(
    base: MockMetrics,
    current: MockMetrics,
  ): MockChanges {
    return {
      totalMockChange: current.totalMocks - base.totalMocks,
      mocksByTypeChange: this.calculateTypeChanges(
        base.mocksByType,
        current.mocksByType,
      ),
      newAntiPatterns: current.antiPatterns.filter(
        (pattern) =>
          !base.antiPatterns.some(
            (basePattern) =>
              basePattern.type === pattern.type &&
              basePattern.location === pattern.location,
          ),
      ),
      qualityScoreChange: current.qualityScore - base.qualityScore,
      filesWithIncreasedMocks: this.findFilesWithIncreasedMocks(
        base.mocksByFile,
        current.mocksByFile,
      ),
    }
  }

  private assessRiskLevel(changes: MockChanges): RiskAssessment {
    let riskScore = 0
    const risks: string[] = []

    // High risk: Adding many mocks
    if (changes.totalMockChange > 10) {
      riskScore += 30
      risks.push(`Added ${changes.totalMockChange} mocks`)
    }

    // Medium risk: Adding internal mocks
    if (changes.mocksByTypeChange[MockType.INTERNAL] > 0) {
      riskScore += 20
      risks.push(
        `Added ${changes.mocksByTypeChange[MockType.INTERNAL]} internal mocks`,
      )
    }

    // High risk: New critical anti-patterns
    const criticalAntiPatterns = changes.newAntiPatterns.filter(
      (p) => p.severity === 'critical',
    )
    if (criticalAntiPatterns.length > 0) {
      riskScore += 40
      risks.push(
        `Introduced ${criticalAntiPatterns.length} critical anti-patterns`,
      )
    }

    // Medium risk: Quality score decrease
    if (changes.qualityScoreChange < -10) {
      riskScore += 15
      risks.push(
        `Quality score decreased by ${Math.abs(changes.qualityScoreChange)}`,
      )
    }

    const level =
      riskScore >= 40
        ? 'critical'
        : riskScore >= 25
          ? 'high'
          : riskScore >= 10
            ? 'medium'
            : 'low'

    return { level, score: riskScore, risks }
  }

  generatePullRequestComment(analysis: PullRequestAnalysis): string {
    const riskEmoji = {
      low: '‚úÖ',
      medium: '‚ö†Ô∏è',
      high: 'üî∂',
      critical: 'üö®',
    }

    return `
## Mock Usage Analysis ${riskEmoji[analysis.riskAssessment.level]}

### Summary
- **Total Mock Change**: ${analysis.mockChanges.totalMockChange > 0 ? '+' : ''}${analysis.mockChanges.totalMockChange}
- **Quality Score Change**: ${analysis.mockChanges.qualityScoreChange > 0 ? '+' : ''}${analysis.mockChanges.qualityScoreChange}
- **Risk Level**: ${analysis.riskAssessment.level.toUpperCase()}

### Changes by Type
${Object.entries(analysis.mockChanges.mocksByTypeChange)
  .filter(([_, change]) => change !== 0)
  .map(([type, change]) => `- **${type}**: ${change > 0 ? '+' : ''}${change}`)
  .join('\n')}

${
  analysis.mockChanges.newAntiPatterns.length > 0
    ? `
### New Anti-Patterns Detected
${analysis.mockChanges.newAntiPatterns
  .map(
    (pattern) =>
      `- **${pattern.type}** (${pattern.severity}): ${pattern.description}`,
  )
  .join('\n')}
`
    : ''
}

${
  analysis.mockChanges.filesWithIncreasedMocks.length > 0
    ? `
### Files with Increased Mocks
${analysis.mockChanges.filesWithIncreasedMocks
  .map((file) => `- \`${file.path}\`: +${file.increase} mocks`)
  .join('\n')}
`
    : ''
}

### Recommendations
${analysis.recommendations.map((rec) => `- ${rec}`).join('\n')}

${
  analysis.shouldBlock
    ? `
### ‚ö†Ô∏è Action Required
This PR introduces significant mock usage concerns that should be addressed before merging.
`
    : ''
}

---
*This analysis was generated by the Mock Usage Monitor. For questions, see the [testing guidelines](link-to-guidelines).*
    `
  }
}

interface PullRequestAnalysis {
  baseBranch: string
  currentBranch: string
  mockChanges: MockChanges
  riskAssessment: RiskAssessment
  recommendations: string[]
  shouldBlock: boolean
}

interface MockChanges {
  totalMockChange: number
  mocksByTypeChange: Record<MockType, number>
  newAntiPatterns: AntiPattern[]
  qualityScoreChange: number
  filesWithIncreasedMocks: Array<{ path: string; increase: number }>
}

interface RiskAssessment {
  level: 'low' | 'medium' | 'high' | 'critical'
  score: number
  risks: string[]
}
```

### 3. Reporting Dashboard

```typescript
// src/monitoring/mock-reporting-dashboard.ts

export class MockReportingDashboard {
  async generateDailyReport(metrics: MockMetrics): Promise<DailyReport> {
    return {
      date: new Date().toISOString().split('T')[0],
      summary: this.generateSummary(metrics),
      trends: this.generateTrendAnalysis(metrics),
      antiPatterns: this.generateAntiPatternReport(metrics.antiPatterns),
      recommendations: this.generateDailyRecommendations(metrics),
      teamMetrics: await this.generateTeamMetrics(metrics),
    }
  }

  async generateWeeklyReport(
    weeklyMetrics: MockMetrics[],
  ): Promise<WeeklyReport> {
    const aggregated = this.aggregateWeeklyMetrics(weeklyMetrics)

    return {
      weekStart: this.getWeekStart().toISOString().split('T')[0],
      weekEnd: new Date().toISOString().split('T')[0],
      summary: this.generateWeeklySummary(aggregated),
      trends: this.generateWeeklyTrends(weeklyMetrics),
      achievements: this.identifyAchievements(weeklyMetrics),
      concerns: this.identifyConcerns(weeklyMetrics),
      teamProgress: await this.generateTeamProgress(weeklyMetrics),
      actionItems: this.generateActionItems(aggregated),
    }
  }

  async generateExecutiveSummary(
    monthlyData: MockMetrics[],
  ): Promise<ExecutiveSummary> {
    const current = monthlyData[monthlyData.length - 1]
    const previous = monthlyData[0]

    return {
      period: `${previous.timestamp.split('T')[0]} to ${current.timestamp.split('T')[0]}`,
      keyMetrics: {
        totalMockReduction: previous.totalMocks - current.totalMocks,
        qualityImprovement: current.qualityScore - previous.qualityScore,
        antiPatternReduction:
          previous.antiPatterns.length - current.antiPatterns.length,
        testReliabilityImprovement:
          await this.calculateReliabilityImprovement(monthlyData),
      },
      businessImpact: this.calculateBusinessImpact(monthlyData),
      riskAssessment: this.assessOverallRisk(current),
      strategicRecommendations:
        this.generateStrategicRecommendations(monthlyData),
    }
  }

  generateHtmlDashboard(metrics: MockMetrics): string {
    return `
<!DOCTYPE html>
<html>
<head>
    <title>Mock Usage Dashboard</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .metric-card { background: #f5f5f5; padding: 20px; margin: 10px 0; border-radius: 8px; }
        .critical { border-left: 5px solid #e74c3c; }
        .warning { border-left: 5px solid #f39c12; }
        .success { border-left: 5px solid #27ae60; }
        .chart-container { width: 400px; height: 300px; margin: 20px 0; }
    </style>
</head>
<body>
    <h1>Mock Usage Dashboard</h1>

    <div class="metric-card ${this.getQualityClass(metrics.qualityScore)}">
        <h2>Overall Quality Score</h2>
        <h1>${metrics.qualityScore}/100</h1>
        <p>Total Mocks: ${metrics.totalMocks}</p>
        <p>Last Updated: ${new Date(metrics.timestamp).toLocaleString()}</p>
    </div>

    <div class="metric-card">
        <h2>Mock Distribution by Type</h2>
        <canvas id="mockTypeChart" class="chart-container"></canvas>
    </div>

    <div class="metric-card">
        <h2>Mock Distribution by Test Tier</h2>
        <canvas id="mockTierChart" class="chart-container"></canvas>
    </div>

    <div class="metric-card">
        <h2>Anti-Patterns Detected</h2>
        ${this.generateAntiPatternList(metrics.antiPatterns)}
    </div>

    <div class="metric-card">
        <h2>Top Files by Mock Count</h2>
        ${this.generateTopFilesList(metrics.mocksByFile)}
    </div>

    <script>
        ${this.generateChartScripts(metrics)}
    </script>
</body>
</html>
    `
  }

  private generateChartScripts(metrics: MockMetrics): string {
    return `
        // Mock Type Distribution Chart
        new Chart(document.getElementById('mockTypeChart'), {
            type: 'doughnut',
            data: {
                labels: ${JSON.stringify(Object.keys(metrics.mocksByType))},
                datasets: [{
                    data: ${JSON.stringify(Object.values(metrics.mocksByType))},
                    backgroundColor: [
                        '#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6', '#1abc9c'
                    ]
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false
            }
        });

        // Mock Tier Distribution Chart
        new Chart(document.getElementById('mockTierChart'), {
            type: 'bar',
            data: {
                labels: ${JSON.stringify(Object.keys(metrics.mocksByTier))},
                datasets: [{
                    label: 'Mock Count',
                    data: ${JSON.stringify(Object.values(metrics.mocksByTier))},
                    backgroundColor: '#3498db'
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true
                    }
                }
            }
        });
    `
  }

  private generateAntiPatternList(antiPatterns: AntiPattern[]): string {
    if (antiPatterns.length === 0) {
      return '<p class="success">üéâ No anti-patterns detected!</p>'
    }

    return antiPatterns
      .map(
        (pattern) => `
        <div class="metric-card ${pattern.severity}">
            <h4>${pattern.type} (${pattern.severity})</h4>
            <p>${pattern.description}</p>
            <p><strong>Recommendation:</strong> ${pattern.recommendation}</p>
            <p><strong>Location:</strong> ${pattern.location}</p>
        </div>
    `,
      )
      .join('')
  }

  private generateTopFilesList(mocksByFile: Record<string, number>): string {
    const sortedFiles = Object.entries(mocksByFile)
      .sort(([, a], [, b]) => b - a)
      .slice(0, 10)

    return `
        <ul>
            ${sortedFiles
              .map(
                ([file, count]) => `
                <li><code>${file}</code>: ${count} mocks</li>
            `,
              )
              .join('')}
        </ul>
    `
  }
}

interface DailyReport {
  date: string
  summary: ReportSummary
  trends: TrendSummary
  antiPatterns: AntiPatternSummary
  recommendations: string[]
  teamMetrics: TeamMetrics
}

interface WeeklyReport {
  weekStart: string
  weekEnd: string
  summary: WeeklySummary
  trends: WeeklyTrends
  achievements: Achievement[]
  concerns: Concern[]
  teamProgress: TeamProgress
  actionItems: ActionItem[]
}

interface ExecutiveSummary {
  period: string
  keyMetrics: KeyMetrics
  businessImpact: BusinessImpact
  riskAssessment: OverallRisk
  strategicRecommendations: StrategicRecommendation[]
}
```

### 4. CI/CD Integration

```typescript
// scripts/ci-mock-check.ts

export class CIMockChecker {
  async runCICheck(): Promise<CICheckResult> {
    const currentMetrics = await this.collectCurrentMetrics()
    const thresholds = this.loadThresholds()

    const violations = this.checkThresholds(currentMetrics, thresholds)
    const pullRequestAnalysis = await this.analyzePullRequest()

    const result: CICheckResult = {
      success: violations.length === 0 && !pullRequestAnalysis.shouldBlock,
      violations,
      metrics: currentMetrics,
      pullRequestAnalysis,
      recommendations: this.generateCIRecommendations(
        violations,
        pullRequestAnalysis,
      ),
    }

    await this.publishResults(result)
    return result
  }

  private checkThresholds(
    metrics: MockMetrics,
    thresholds: MockThresholds,
  ): Violation[] {
    const violations: Violation[] = []

    if (metrics.totalMocks > thresholds.maxTotalMocks) {
      violations.push({
        type: 'total-mocks-exceeded',
        severity: 'high',
        current: metrics.totalMocks,
        threshold: thresholds.maxTotalMocks,
        message: `Total mock count (${metrics.totalMocks}) exceeds threshold (${thresholds.maxTotalMocks})`,
      })
    }

    if (metrics.qualityScore < thresholds.minQualityScore) {
      violations.push({
        type: 'quality-score-below-threshold',
        severity: 'medium',
        current: metrics.qualityScore,
        threshold: thresholds.minQualityScore,
        message: `Quality score (${metrics.qualityScore}) below threshold (${thresholds.minQualityScore})`,
      })
    }

    const criticalAntiPatterns = metrics.antiPatterns.filter(
      (p) => p.severity === 'critical',
    )
    if (criticalAntiPatterns.length > 0) {
      violations.push({
        type: 'critical-anti-patterns',
        severity: 'critical',
        current: criticalAntiPatterns.length,
        threshold: 0,
        message: `${criticalAntiPatterns.length} critical anti-pattern(s) detected`,
      })
    }

    return violations
  }

  async publishResults(result: CICheckResult): Promise<void> {
    // Publish to CI system
    if (process.env.CI) {
      await this.publishToCISystem(result)
    }

    // Post to PR if applicable
    if (process.env.GITHUB_EVENT_NAME === 'pull_request') {
      await this.postToPullRequest(result)
    }

    // Send notifications if violations
    if (!result.success) {
      await this.sendNotifications(result)
    }

    // Save results for tracking
    await this.saveResults(result)
  }

  private generateCIOutput(result: CICheckResult): string {
    if (result.success) {
      return `
‚úÖ Mock Usage Check: PASSED

üìä Current Metrics:
- Total Mocks: ${result.metrics.totalMocks}
- Quality Score: ${result.metrics.qualityScore}/100
- Anti-Patterns: ${result.metrics.antiPatterns.length}

üéØ All thresholds met. Great job maintaining healthy testing practices!
      `
    }

    return `
‚ùå Mock Usage Check: FAILED

üìä Current Metrics:
- Total Mocks: ${result.metrics.totalMocks}
- Quality Score: ${result.metrics.qualityScore}/100
- Anti-Patterns: ${result.metrics.antiPatterns.length}

üö® Violations Detected:
${result.violations.map((v) => `- ${v.message}`).join('\n')}

üí° Recommendations:
${result.recommendations.map((r) => `- ${r}`).join('\n')}

See the Mock Usage Guide for help: [link-to-guide]
    `
  }
}

interface CICheckResult {
  success: boolean
  violations: Violation[]
  metrics: MockMetrics
  pullRequestAnalysis?: PullRequestAnalysis
  recommendations: string[]
}

interface Violation {
  type: string
  severity: 'low' | 'medium' | 'high' | 'critical'
  current: number
  threshold: number
  message: string
}
```

## Acceptance Criteria

- [ ] Mock usage tracking system implemented and collecting metrics
- [ ] Anti-pattern detection system identifies common mock problems
- [ ] Quality scoring system provides actionable feedback
- [ ] Pull request analysis prevents mock regression
- [ ] Daily, weekly, and executive reporting systems created
- [ ] HTML dashboard provides real-time mock usage visualization
- [ ] CI/CD integration blocks problematic mock usage
- [ ] Threshold monitoring system with configurable limits
- [ ] Trend analysis identifies patterns over time
- [ ] Notification system alerts team to concerning patterns
- [ ] Historical data persistence for long-term analysis
- [ ] Team metrics and progress tracking implemented

## Benefits

1. **Continuous Improvement**: Ongoing monitoring prevents mock creep
2. **Data-Driven Decisions**: Metrics guide mock reduction strategy
3. **Team Awareness**: Regular reports keep team focused on quality
4. **Automated Prevention**: CI checks prevent regression
5. **Strategic Insights**: Executive reporting shows business impact

## Notes

- Start with basic metrics and expand based on team needs
- Configure thresholds based on current baseline and improvement goals
- Ensure reporting is actionable and not just informational
- Integrate with existing team communication channels
- Consider privacy and security when collecting and storing metrics
