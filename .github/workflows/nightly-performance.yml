name: Nightly Performance Benchmarks

on:
  # Temporarily disabled scheduled runs until main branch issues are resolved
  # schedule:
  #   # Run at 2 AM UTC daily
  #   - cron: "0 2 * * *"
  workflow_dispatch: # Allow manual trigger

env:
  NODE_VERSION: "20.18.1"
  PNPM_VERSION: "9.15.4"
  FORCE_COLOR: 3
  # Vercel Remote Cache for consistent benchmark results
  TURBO_TOKEN: ${{ secrets.TURBO_TOKEN }}
  TURBO_TEAM: ${{ vars.TURBO_TEAM }}
  TURBO_REMOTE_CACHE_SIGNATURE_KEY: ${{ secrets.TURBO_REMOTE_CACHE_SIGNATURE_KEY }}

jobs:
  performance:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "pnpm"

      - name: Install Dependencies
        run: pnpm install --frozen-lockfile
        env:
          NODE_ENV: development

      - name: Install Hyperfine
        run: |
          wget https://github.com/sharkdp/hyperfine/releases/download/v1.18.0/hyperfine_1.18.0_amd64.deb
          sudo dpkg -i hyperfine_1.18.0_amd64.deb

      - name: Run Performance Benchmarks
        run: |
          echo "## âš¡ Nightly Performance Benchmarks - $(date)" > perf-results.md
          echo "" >> perf-results.md
          echo "### Build Performance" >> perf-results.md
          hyperfine --warmup 1 'pnpm run build' --export-markdown perf-build.md
          cat perf-build.md >> perf-results.md
          echo "" >> perf-results.md
          echo "### Test Performance" >> perf-results.md
          hyperfine --warmup 2 'pnpm run test' --export-markdown perf-test.md
          cat perf-test.md >> perf-results.md
          echo "" >> perf-results.md
          echo "### Startup Performance" >> perf-results.md
          hyperfine --warmup 3 'pnpm run server:start' --export-markdown perf-startup.md
          cat perf-startup.md >> perf-results.md

      - name: Create Issue on Performance Regression
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = fs.readFileSync('perf-results.md', 'utf8');

            // Create an issue with the performance results
            // This could be enhanced with threshold checks for regression detection
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Nightly Performance Report - ${new Date().toISOString().split('T')[0]}`,
              body: results,
              labels: ['performance', 'automated']
            });

      - name: Upload Performance Results
        uses: actions/upload-artifact@v4
        with:
          name: performance-results-${{ github.run_number }}
          path: |
            perf-results.md
            perf-build.md
            perf-test.md
            perf-startup.md
          retention-days: 30
